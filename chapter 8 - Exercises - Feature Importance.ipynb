{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, log_loss, accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 8 - code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNIPPET 8.7 CREATING A SYNTHETIC DATASET\n",
    "\n",
    "def getTestData(n_features=40,n_informative=10,n_redundant=10,n_samples=10000):\n",
    "    \n",
    "    # generate a random dataset for a classification problem\n",
    "    from sklearn.datasets import make_classification\n",
    "    \n",
    "    trnsX,cont=make_classification(n_samples=n_samples,n_features=n_features,n_informative=n_informative,\n",
    "                                   n_redundant=n_redundant,random_state=0, shuffle=False)\n",
    "    \n",
    "    df0=pd.DatetimeIndex(periods=n_samples,freq=pd.tseries.offsets.BDay(), end=pd.datetime.today())\n",
    "    \n",
    "    trnsX,cont=pd.DataFrame(trnsX,index=df0),pd.Series(cont,index=df0).to_frame('bin')\n",
    "    \n",
    "    df0=['I_'+str(i) for i in range(n_informative)]+['R_'+str(i) for i in range(n_redundant)]\n",
    "    \n",
    "    df0+=['N_'+str(i) for i in range(n_features-len(df0))]\n",
    "    \n",
    "    trnsX.columns=df0\n",
    "    \n",
    "    cont['w']=1./cont.shape[0]\n",
    "    cont['t1']=pd.Series(cont.index,index=cont.index)\n",
    "    \n",
    "    return trnsX,cont\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "# This version is for large n_samples. It changes the frequency of the index of the dataset.\n",
    "\n",
    "def getTestData_largeSet(n_features=40,n_informative=10,n_redundant=10,n_samples=10000):\n",
    "    \n",
    "    # generate a random dataset for a classification problem\n",
    "    from sklearn.datasets import make_classification\n",
    "    \n",
    "    trnsX,cont=make_classification(n_samples=n_samples,n_features=n_features,n_informative=n_informative,\n",
    "                                   n_redundant=n_redundant,random_state=0, shuffle=False)\n",
    "    \n",
    "    cond = 0\n",
    "    \n",
    "    if (n_samples <= 1000F0):       \n",
    "        df0=pd.DatetimeIndex(periods=n_samples,freq=pd.tseries.offsets.BDay(), end=pd.datetime.today())      # original\n",
    "        \n",
    "    elif (n_samples>10000) & (n_samples<=100000):\n",
    "        df0=pd.DatetimeIndex(periods=n_samples,freq=pd.tseries.offsets.Minute(60), end=pd.datetime.today())   #...mc\n",
    "        \n",
    "    elif (n_samples>100000) & (n_samples<=400000):\n",
    "        df0=pd.DatetimeIndex(periods=n_samples,freq=pd.tseries.offsets.Minute(30), end=pd.datetime.today())   #...mc\n",
    "        \n",
    "    else:\n",
    "        df0=pd.DatetimeIndex(periods=n_samples,freq=pd.tseries.offsets.Minute(15), end=pd.datetime.today())   #...mc\n",
    "        \n",
    "                \n",
    "        \n",
    "    trnsX,cont=pd.DataFrame(trnsX,index=df0),pd.Series(cont,index=df0).to_frame('bin')\n",
    "    \n",
    "    df0=['I_'+str(i) for i in range(n_informative)]+['R_'+str(i) for i in range(n_redundant)]\n",
    "    \n",
    "    df0+=['N_'+str(i) for i in range(n_features-len(df0))]\n",
    "    \n",
    "    trnsX.columns=df0\n",
    "    cont['w']=1./cont.shape[0]\n",
    "    cont['t1']=pd.Series(cont.index,index=cont.index)\n",
    "    \n",
    "    return trnsX,cont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNIPPET 8.5 COMPUTATION OF ORTHOGONAL FEATURES\n",
    "\n",
    "def get_eVec(dot,varThres):\n",
    "   \n",
    "    # compute eVec from dot prod matrix, reduce dimension\n",
    "    eVal,eVec=np.linalg.eigh(dot)\n",
    "    idx=eVal.argsort()[::-1] # arguments for sorting eVal desc\n",
    "    eVal,eVec=eVal[idx],eVec[:,idx]\n",
    "    \n",
    "    #2) only positive eVals\n",
    "    eVal=pd.Series(eVal,index=['PC_'+str(i+1) for i in range(eVal.shape[0])])\n",
    "    eVec=pd.DataFrame(eVec,index=dot.index,columns=eVal.index)\n",
    "    eVec=eVec.loc[:,eVal.index]\n",
    "    \n",
    "    #3) reduce dimension, form PCs\n",
    "    cumVar=eVal.cumsum()/eVal.sum()\n",
    "    dim=cumVar.values.searchsorted(varThres)\n",
    "    eVal,eVec=eVal.iloc[:dim+1],eVec.iloc[:,:dim+1]\n",
    "    \n",
    "    return eVal,eVec\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "def orthoFeats(dfX,varThres=.95):\n",
    "   \n",
    "    # Given a dataframe dfX of features, compute orthofeatures dfP\n",
    "    dfZ=dfX.sub(dfX.mean(),axis=1).div(dfX.std(),axis=1) # standardize\n",
    "    dot=pd.DataFrame(np.dot(dfZ.T,dfZ),index=dfX.columns,columns=dfX.columns)       # esta matriz es multiplo de la matriz de correlaciÃ³n\n",
    "    eVal,eVec=get_eVec(dot,varThres)\n",
    "    \n",
    "    #dfP=np.dot(dfZ,eVec)                #original\n",
    "    dfP = pd.DataFrame(np.dot(dfZ,eVec), index=dfX.index) \n",
    "     \n",
    "    return dfP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNIPPET 8.2 MDI FEATURE IMPORTANCE\n",
    "\n",
    "def featImpMDI(fit,featNames):\n",
    "    \n",
    "    # feat importance based on IS mean impurity reduction\n",
    "    df0={i:tree.feature_importances_ for i,tree in enumerate(fit.estimators_)}\n",
    "    df0=pd.DataFrame.from_dict(df0,orient='index')\n",
    "    df0.columns=featNames\n",
    "    df0=df0.replace(0,np.nan) # because max_features=1\n",
    "    imp=pd.concat({'mean':df0.mean(),'std':df0.std()*df0.shape[0]**-.5},axis=1)\n",
    "    imp/=imp['mean'].sum()\n",
    "    \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNIPPET 8.3 MDA FEATURE IMPORTANCE\n",
    "\n",
    "def featImpMDA(clf,X,y,cv,sample_weight,t1,pctEmbargo,scoring='neg_log_loss'):\n",
    "    \n",
    "    # feat importance based on OOS score reduction\n",
    "    \n",
    "    if scoring not in ['neg_log_loss','accuracy']:\n",
    "        raise Exception('wrong scoring method.')\n",
    "    from sklearn.metrics import log_loss,accuracy_score\n",
    "    \n",
    "    cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo) # purged cv\n",
    "    scr0,scr1=pd.Series(),pd.DataFrame(columns=X.columns)\n",
    "    \n",
    "    for i,(train,test) in enumerate(cvGen.split(X=X)):\n",
    "        X0,y0,w0=X.iloc[train,:],y.iloc[train],sample_weight.iloc[train]\n",
    "        X1,y1,w1=X.iloc[test,:],y.iloc[test],sample_weight.iloc[test]\n",
    "        fit=clf.fit(X=X0,y=y0,sample_weight=w0.values)\n",
    "        \n",
    "        if scoring=='neg_log_loss':\n",
    "            prob=fit.predict_proba(X1)\n",
    "            scr0.loc[i]=-log_loss(y1,prob,sample_weight=w1.values,labels=clf.classes_)\n",
    "        else:\n",
    "            pred=fit.predict(X1)\n",
    "            scr0.loc[i]=accuracy_score(y1,pred,sample_weight=w1.values)\n",
    "        \n",
    "        for j in X.columns:\n",
    "            X1_=X1.copy(deep=True)\n",
    "            np.random.shuffle(X1_[j].values) # permutation of a single column\n",
    "            \n",
    "            if scoring=='neg_log_loss':\n",
    "                prob=fit.predict_proba(X1_)\n",
    "                scr1.loc[i,j]=-log_loss(y1,prob,sample_weight=w1.values,labels=clf.classes_)\n",
    "            else:\n",
    "                pred=fit.predict(X1_)\n",
    "                scr1.loc[i,j]=accuracy_score(y1,pred,sample_weight=w1.values)\n",
    "    \n",
    "    imp=(-scr1).add(scr0,axis=0)\n",
    "    \n",
    "    if scoring=='neg_log_loss':\n",
    "        imp=imp/-scr1\n",
    "    else:\n",
    "        imp=imp/(1.-scr1)\n",
    "    \n",
    "    imp=pd.concat({'mean':imp.mean(),'std':imp.std()*imp.shape[0]**-.5},axis=1)\n",
    "    \n",
    "    return imp,scr0.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNIPPET 8.4 IMPLEMENTATION OF SFI\n",
    "\n",
    "def auxFeatImpSFI(featNames,clf,trnsX,cont,scoring,cvGen):\n",
    "    \n",
    "    imp=pd.DataFrame(columns=['mean','std'])\n",
    "    \n",
    "    for featName in featNames:\n",
    "        \n",
    "        df0=cvScore(clf,X=trnsX[[featName]],y=cont['bin'],sample_weight=cont['w'],\n",
    "                    scoring=scoring,cvGen=cvGen)\n",
    "        imp.loc[featName,'mean']=df0.mean()\n",
    "        imp.loc[featName,'std']=df0.std()*df0.shape[0]**-.5\n",
    "        \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNIPPET 8.8 CALLING FEATURE IMPORTANCE FOR ANY METHOD\n",
    "\n",
    "def featImportance(trnsX,cont,n_estimators=1000,cv=10,max_samples=1.,numThreads=24,\n",
    "                   pctEmbargo=0,scoring='accuracy',method='SFI',minWLeaf=0.,**kargs):\n",
    "    \n",
    "    # feature importance from a random forest\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    from mpEngine import mpPandasObj\n",
    "    \n",
    "    n_jobs=(-1 if numThreads>1 else 1) # run 1 thread with ht_helper in dirac1\n",
    "    \n",
    "    #1) prepare classifier,cv. max_features=1, to prevent masking\n",
    "    clf=DecisionTreeClassifier(criterion='entropy',max_features=1,\n",
    "    class_weight='balanced',min_weight_fraction_leaf=minWLeaf)\n",
    "    clf=BaggingClassifier(base_estimator=clf,n_estimators=n_estimators,\n",
    "    max_features=1.,max_samples=max_samples,oob_score=True,n_jobs=n_jobs)\n",
    "    fit=clf.fit(X=trnsX,y=cont['bin'],sample_weight=cont['w'].values)\n",
    "    oob=fit.oob_score_\n",
    "    \n",
    "    if method=='MDI':\n",
    "        imp=featImpMDI(fit,featNames=trnsX.columns)\n",
    "        oos=cvScore(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],\n",
    "                    t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring).mean()\n",
    "        \n",
    "    elif method=='MDA':\n",
    "        imp,oos=featImpMDA(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],\n",
    "                           t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring)\n",
    "    \n",
    "    elif method=='SFI':\n",
    "        cvGen=PurgedKFold(n_splits=cv,t1=cont['t1'],pctEmbargo=pctEmbargo)\n",
    "        oos=cvScore(clf,X=trnsX,y=cont['bin'],sample_weight=cont['w'],scoring=scoring,\n",
    "                    cvGen=cvGen).mean()\n",
    "        clf.n_jobs=1 # paralellize auxFeatImpSFI rather than clf\n",
    "        imp=mpPandasObj(auxFeatImpSFI,('featNames',trnsX.columns),numThreads,\n",
    "                        clf=clf,trnsX=trnsX,cont=cont,scoring=scoring,cvGen=cvGen)\n",
    "        \n",
    "    return imp,oob,oos\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "def featImportance_2_mc(trnsX,cont,n_estimators=1000,cv=10,max_samples=1.,\n",
    "                   pctEmbargo=0,scoring='accuracy',method='SFI',minWLeaf=0.,**kargs):\n",
    "    \n",
    "    # feature importance from a random forest\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    #from mpEngine import mpPandasObj                  #mc\n",
    "    \n",
    "    # n_jobs=(-1 if numThreads>1 else 1) # run 1 thread with ht_helper in dirac1    ...#mc\n",
    "    \n",
    "    #1) prepare classifier,cv. max_features=1, to prevent masking\n",
    "    clf=DecisionTreeClassifier(criterion='entropy',max_features=1,class_weight='balanced',\n",
    "                               min_weight_fraction_leaf=minWLeaf)\n",
    "    #clf=BaggingClassifier(base_estimator=clf,n_estimators=n_estimators,            ...#mc\n",
    "    #                        max_features=1.,max_samples=max_samples,oob_score=True,n_jobs=n_jobs)\n",
    "    \n",
    "    clf=BaggingClassifier(base_estimator=clf,n_estimators=n_estimators,max_features=1.,\n",
    "                          max_samples=max_samples,oob_score=True)\n",
    "    fit=clf.fit(X=trnsX,y=cont['bin'],sample_weight=cont['w'].values)\n",
    "    oob=fit.oob_score_\n",
    "    \n",
    "    if method=='MDI':\n",
    "        imp=featImpMDI(fit,featNames=trnsX.columns)\n",
    "        \n",
    "        #oos=cvScore(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],                     #original\n",
    "        #            t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring).mean()\n",
    "        \n",
    "        oos = cvScore2_mc(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],                # mc\n",
    "                          t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring).mean()\n",
    "              \n",
    "    elif method=='MDA':\n",
    "        imp,oos=featImpMDA(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],\n",
    "                           t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring)\n",
    "    \n",
    "    elif method=='SFI':\n",
    "        cvGen=PurgedKFold(n_splits=cv,t1=cont['t1'],pctEmbargo=pctEmbargo)\n",
    "        \n",
    "        #oos=cvScore(clf,X=trnsX,y=cont['bin'],sample_weight=cont['w'],scoring=scoring,           #original\n",
    "        #            cvGen=cvGen).mean()\n",
    "        \n",
    "        oos = cvScore2_mc(clf, X=trnsX,y=cont['bin'],sample_weight=cont['w'],scoring=scoring,     #...mc\n",
    "                                cvGen=cvGen).mean()\n",
    "        \n",
    "        #clf.n_jobs=1 # paralellize auxFeatImpSFI rather than clf                                 # original\n",
    "        #imp=mpPandasObj(auxFeatImpSFI,('featNames',trnsX.columns),numThreads,\n",
    "        #                clf=clf,trnsX=trnsX,cont=cont,scoring=scoring,cvGen=cvGen)\n",
    "        \n",
    "        \n",
    "        imp = auxFeatImpSFI(featNames=trnsX.columns, clf=clf, trnsX=trnsX, cont=cont, scoring=scoring, cvGen=cvGen)     #mc\n",
    "        \n",
    "        \n",
    "    return imp,oob,oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNIPPET 7.3 CROSS-VALIDATION CLASS WHEN OBSERVATIONS OVERLAP\n",
    "\n",
    "from sklearn.model_selection._split import _BaseKFold\n",
    "\n",
    "class PurgedKFold(_BaseKFold):\n",
    "    '''\n",
    "    Extend KFold class to work with labels that span intervals\n",
    "    The train is purged of observations overlapping test-label intervals\n",
    "    Test set is assumed contiguous (shuffle=False), w/o training samples in between\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_splits=3, t1=None, pctEmbargo=0.):\n",
    "        \n",
    "        if not isinstance(t1, pd.Series):\n",
    "            raise ValueError('Label Through Dates must be a pd.Series')\n",
    "            \n",
    "        super(PurgedKFold,self).__init__(n_splits,shuffle=False,random_state=None)\n",
    "        self.t1=t1\n",
    "        self.pctEmbargo=pctEmbargo\n",
    "    \n",
    "    \n",
    "    def split(self,X,y=None,groups=None):\n",
    "        \n",
    "        if (X.index==self.t1.index).sum()!=len(self.t1):\n",
    "            raise ValueError('X and ThruDateValues must have the same index')\n",
    "            \n",
    "        indices=np.arange(X.shape[0])\n",
    "        mbrg=int(X.shape[0]*self.pctEmbargo)\n",
    "        test_starts=[(i[0],i[-1]+1) for i in \\\n",
    "            np.array_split(np.arange(X.shape[0]),self.n_splits)]\n",
    "        \n",
    "        for i,j in test_starts:\n",
    "            \n",
    "            t0=self.t1.index[i] # start of test set\n",
    "            test_indices=indices[i:j]\n",
    "            maxT1Idx=self.t1.index.searchsorted(self.t1[test_indices].max())\n",
    "            train_indices=self.t1.index.searchsorted(self.t1[self.t1<=t0].index)\n",
    "            \n",
    "            if maxT1Idx<X.shape[0]: # right train (with embargo)\n",
    "                train_indices=np.concatenate((train_indices,indices[maxT1Idx+mbrg:]))\n",
    "                \n",
    "            yield train_indices,test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNIPPET 7.4 USING THE PurgedKFold CLASS\n",
    "\n",
    "def cvScore(clf, X, y, sample_weight, scoring='neg_log_loss', t1=None, cv=None, cvGen=None, pctEmbargo=None):\n",
    "    \n",
    "    if scoring not in ['neg_log_loss','accuracy']:\n",
    "        raise Exception('wrong scoring method.')\n",
    "    \n",
    "    from sklearn.metrics import log_loss,accuracy_score\n",
    "    #from clfSequential import PurgedKFold\n",
    "    \n",
    "    \n",
    "    if cvGen is None:\n",
    "        \n",
    "        cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo) # purged\n",
    "    \n",
    "    '''\n",
    "    if cvGen is None:\n",
    "        if pctEmbargo==None:\n",
    "            cvGen = PurgedKFold(n_splits=cv, t1=t1)\n",
    "    else:\n",
    "            cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo) # purged\n",
    "    '''\n",
    "    \n",
    "    score=[]\n",
    "    \n",
    "    for train,test in cvGen.split(X=X):    # book\n",
    "            \n",
    "        fit=clf.fit(X=X.iloc[train,:],y=y.iloc[train],sample_weight=sample_weight.iloc[train].values) # book\n",
    "        \n",
    "        #fit=clf.fit(X=X.iloc[train,:],y=y.iloc[train].values.reshape(-1),\\\n",
    "        #            sample_weight=sample_weight.iloc[train].values.reshape(-1))   # mc\n",
    "        \n",
    "        \n",
    "        if scoring=='neg_log_loss':\n",
    "            prob=fit.predict_proba(X.iloc[test,:])\n",
    "            score_=-log_loss(y.iloc[test],prob,sample_weight=sample_weight.iloc[test].values,labels=clf.classes_)\n",
    "        else:\n",
    "            pred=fit.predict(X.iloc[test,:])\n",
    "            score_=accuracy_score(y.iloc[test],pred,sample_weight= \\\n",
    "                sample_weight.iloc[test].values)\n",
    "            \n",
    "        score.append(score_)\n",
    "        \n",
    "    return np.array(score)\n",
    "\n",
    "\n",
    "# ----------------------- --------------------- ------------------------- ---------------------------\n",
    "\n",
    "\n",
    "def cvScore2_mc(clf, X, y, sample_weight, scoring='neg_log_loss', t1=None, cv=None, cvGen=None, pctEmbargo=None):\n",
    "    \n",
    "    if scoring not in ['neg_log_loss','accuracy']:\n",
    "        raise Exception('wrong scoring method.')\n",
    "    \n",
    "    from sklearn.metrics import log_loss,accuracy_score\n",
    "    #from clfSequential import PurgedKFold\n",
    "    \n",
    "    if cvGen is None:                                   # mc\n",
    "        if pctEmbargo==None:                            # mc\n",
    "            cvGen = PurgedKFold(n_splits=cv, t1=t1)     # mc\n",
    "        else:\n",
    "            cvGen=PurgedKFold(n_splits=cv,t1=t1,pctEmbargo=pctEmbargo) # purged , book\n",
    "    \n",
    "    score=[]\n",
    "    \n",
    "    for train,test in cvGen.split(X=X):    \n",
    "            \n",
    "        #fit=clf.fit(X=X.iloc[train,:],y=y.iloc[train],sample_weight=sample_weight.iloc[train].values) # book\n",
    "        \n",
    "        fit=clf.fit(X=X.iloc[train,:],y=y.iloc[train].values.reshape(-1),\\\n",
    "                    sample_weight=sample_weight.iloc[train].values.reshape(-1))   # mc\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if scoring=='neg_log_loss':\n",
    "            \n",
    "            prob=fit.predict_proba(X.iloc[test,:])\n",
    "            \n",
    "            #score_=-log_loss(y.iloc[test],prob,sample_weight=sample_weight.iloc[test].values,labels=clf.classes_)\n",
    "            score_=-log_loss(y.iloc[test],prob,sample_weight=sample_weight.iloc[test].values.reshape(-1),labels=clf.classes_)\n",
    "            \n",
    "        else:\n",
    "            pred=fit.predict(X.iloc[test,:])\n",
    "            score_=accuracy_score(y.iloc[test],pred,sample_weight= \\\n",
    "                sample_weight.iloc[test].values)\n",
    "            \n",
    "        score.append(score_)\n",
    "        \n",
    "    return np.array(score)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFeatImportance(pathOut,imp,oob,oos,method,tag=0,simNum=0,**kargs):\n",
    "    \n",
    "    # plot mean imp bars with std\n",
    "    mpl.figure(figsize=(10,imp.shape[0]/5.))\n",
    "    imp=imp.sort_values('mean',ascending=True)\n",
    "    ax=imp['mean'].plot(kind='barh',color='b',alpha=.25,xerr=imp['std'],\n",
    "                        error_kw={'ecolor':'r'})\n",
    "    \n",
    "    if method=='MDI':\n",
    "        mpl.xlim([0,imp.sum(axis=1).max()])\n",
    "        mpl.axvline(1./imp.shape[0],linewidth=1,color='r',linestyle='dotted')\n",
    "    \n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    for i,j in zip(ax.patches,imp.index):\n",
    "        ax.text(i.get_width()/2,i.get_y()+i.get_height()/2,j,ha='center',va='center',color='black')\n",
    "    \n",
    "    mpl.title('tag='+tag+' | simNum='+str(simNum)+' | oob='+str(round(oob,4))+ ' | oos='+str(round(oos,4)))\n",
    "    mpl.savefig(pathOut+'featImportance_'+str(simNum)+'.png',dpi=100)\n",
    "    mpl.clf();mpl.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.1) Using the code in Section 8.6:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Generate a dataset (X, y).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'periods'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f2dc0e1694fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrns_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrns_y\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgetTestData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-44672edba6d9>\u001b[0m in \u001b[0;36mgetTestData\u001b[1;34m(n_features, n_informative, n_redundant, n_samples)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                    n_redundant=n_redundant,random_state=0, shuffle=False)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperiods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffsets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBDay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtrnsX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrnsX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcont\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'periods'"
     ]
    }
   ],
   "source": [
    "trns_X, trns_y =  getTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Apply a PCA transformation on X, wich we donote $\\dot{X}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p = orthoFeats(trns_X, varThres = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Compute MDI, MDA, and SFI feature importance on ($\\dot{X}$,y), where the base estimator is RF.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 1000, class_weight = 'balanced_subsample', criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trns_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDI:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDI = False\n",
    "\n",
    "if calculate_MDI:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp, MDI_oob, MDI_oos = featImportance_2_mc(trnsX=X_p, cont= trns_y, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI takes {(end-start)/60} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDA = False\n",
    "\n",
    "if calculate_MDA:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDA_imp, MDA_oob, MDA_oos = featImportance_2_mc(trnsX=X_p, cont= trns_y, n_estimators=1000, cv=10, max_samples=1.,\n",
    "                       pctEmbargo=0, scoring='accuracy', method='MDA', minWLeaf=0.)\n",
    "\n",
    "    end = time.time() \n",
    "    print(f'MDA takes {(end-start)/60} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SFI:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_SFI = False\n",
    "\n",
    "if calculate_SFI:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    SFI_imp, SFI_oob, SFI_oos = featImportance_2_mc(trnsX=X_p, cont= trns_y, n_estimators=1000, cv=10, max_samples=1.,\n",
    "                       pctEmbargo=0, scoring='accuracy', method='SFI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "    print((end-start)/60)\n",
    "    print(f'SFI takes {(end-start)/60/60} hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling the values MDI, MDA and SFI results previously saved:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp = pd.read_csv('MDI_imp.csv')\n",
    "MDI_imp = MDI_imp.drop(['Unnamed: 0'], axis=1)\n",
    "MDI_oob_oos = pd.read_csv('MDI_oob_oos.csv')\n",
    "\n",
    "MDA_imp = pd.read_csv('MDA_imp.csv')\n",
    "MDA_imp = MDA_imp.drop(['Unnamed: 0'], axis=1)\n",
    "MDA_oob_oos = pd.read_csv('MDA_oob_oos.csv')\n",
    "\n",
    "SFI_imp = pd.read_csv('SFI_imp.csv')\n",
    "SFI_imp = SFI_imp.drop(['Unnamed: 0'], axis=1)\n",
    "SFI_oob_oos = pd.read_csv('SFI_oob_oos.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_oob = MDI_oob_oos.iloc[0,1]\n",
    "MDI_oos = MDI_oob_oos.iloc[0,2]\n",
    "\n",
    "print(f'MDI_oob = {MDI_oob}')\n",
    "print(f'MDI_oos= {MDI_oos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDA_oob = MDA_oob_oos.iloc[0,1]\n",
    "MDA_oos = MDA_oob_oos.iloc[0,2]\n",
    "\n",
    "print(f'MDA_oob = {MDA_oob}')\n",
    "print(f'MDA_oos= {MDA_oos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFI_oob = SFI_oob_oos.iloc[0,1]\n",
    "SFI_oos = SFI_oob_oos.iloc[0,2]\n",
    "\n",
    "print(f'SFI_oob = {SFI_oob}')\n",
    "print(f'SFI_oos= {SFI_oos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Do the three methods agree on what features are important? why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_sorted = MDI_imp.sort_values(by=['mean'], ascending=False)\n",
    "MDA_imp_sorted = MDA_imp.sort_values(by=['mean'], ascending=False)\n",
    "SFI_imp_sorted = SFI_imp.sort_values(by=['mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDA_imp_sorted.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp = (pd.DataFrame()\n",
    "               .assign(MDI_components = MDI_imp_sorted.index)\n",
    "               .assign(MDI = MDI_imp_sorted[['mean']].values)\n",
    "               .assign(MDA_components = MDA_imp_sorted.index)\n",
    "               .assign(MDA = MDA_imp_sorted[['mean']].values)\n",
    "               .assign(SFI_components = SFI_imp_sorted.index)\n",
    "               .assign(SFI = SFI_imp_sorted[['mean']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The three methods agree on the selection of the first five components.\n",
    " \n",
    "The MDI and MDA methods extend their selection coincidence up to the ninth component but in different order. This could be due to the orthogonalization of the features through PCA previously applied to the original dataset, which partially solved the substitution effect. For the SFI method substitution effects do not take place and its results may not match completely bacause it computes the OOS performance score of each feature in isolation, nevertheless SFI selected first ten components coincide mostly with MDI and MDA selected components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDI_imp calculation changing the columns order of X_p (PCA) to verify if the selected features match.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for c in reversed(X_p.columns):\n",
    "    cols.append(c)\n",
    "\n",
    "Xp2 = X_p[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDI = False\n",
    "\n",
    "if calculate_MDI:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_Xp2, MDI_oob_Xp2, MDI_oos_Xp2 = featImportance_2_mc(trnsX=X_p2, cont= trns_y, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI takes {(end-start)/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_MDI:\n",
    "    MDI_imp_df = (pd.DataFrame()\n",
    "                  .assign(PCA_Xp = MDI_imp_sorted.index)\n",
    "                  .assign(MDI_imp_Xp = MDI_imp_sorted['mean'].values)\n",
    "                  .assign(PCA_Xp2 = MDI_imp_Xp2.sort_values(by = ['mean'], ascending = False).index)\n",
    "                  .assign(MDI_imp_Xp2 = MDI_imp_Xp2.sort_values(by=['mean'], ascending= False)[['mean']].values)\n",
    "                 )\n",
    "    \n",
    "    MDI_imp_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther previous procedure consits in calculating the Principal Components of the original dataset which returns a new dataset with less features, the ones that contains the 95% of the variation of the data, 28 instead of 40 from the original dataset. Then calculate the MDI_imp to this transformed dataset, change its column order and also calculate the MDI_imp to this dataset in order to verify that in both cases the features or the selected components matches.\n",
    "\n",
    "The result shows that the components selected in both cases are the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2) From exercise 1, generate a new dataset ($\\ddot{X},y$), where $\\ddot{X}$ is a feature union ox X and $\\dot{X}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp = pd.concat([trns_X, X_p,], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2   a) Compute MDI, MDA, and SFI feature importance on ($\\ddot{X},y)$, where the base estimator is RF.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDI_Xpp:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDI = False\n",
    "\n",
    "if calculate_MDI:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_Xpp, MDI_oob_Xpp, MDI_oos_Xpp = featImportance_2_mc(trnsX=X_pp, cont= trns_y, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI takes {(end-start)/60} minutes')\n",
    "    \n",
    "else:\n",
    "    MDI_imp_Xpp = pd.read_csv('MDI_imp_Xpp.csv')\n",
    "    MDI_oob_oos_Xpp = pd.read_csv('MDI_oob_oos_Xpp.csv')[['MDI_oob', 'MDI_oos']]\n",
    "    MDI_oob_Xpp = MDI_oob_oos_Xpp['MDI_oob'].values[0]\n",
    "    MDI_oos_XXP = MDI_oob_oos_Xpp['MDI_oos'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDA_Xpp:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDA = False\n",
    "\n",
    "if calculate_MDA:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDA_imp_Xpp, MDA_oob_Xpp, MDA_oos_Xpp = featImportance_2_mc(trnsX=X_pp, cont= trns_y, n_estimators=1000, cv=10, max_samples=1.,\n",
    "                       pctEmbargo=0, scoring='accuracy', method='MDA', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'MDA takes {(end-start)/60} minutes')\n",
    "    \n",
    "else:\n",
    "    MDA_imp_Xpp = pd.read_csv('MDA_imp_Xpp.csv')\n",
    "    MDA_oob_oos_Xpp = pd.read_csv('MDA_oob_oos_Xpp.csv')[['MDA_oob', 'MDA_oos']]\n",
    "    MDA_oob_Xpp = MDA_oob_oos_Xpp['MDA_oob'].values[0]\n",
    "    MDA_oos_Xpp = MDA_oob_oos_Xpp['MDA_oos'].values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SFI_Xpp:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_SFI = False\n",
    "\n",
    "if calculate_SFI:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    SFI_imp_Xpp, SFI_oob_Xpp, SFI_oos_Xpp = featImportance_2_mc(trnsX=X_pp, cont= trns_y, n_estimators=1000, cv=10, max_samples=1.,\n",
    "                       pctEmbargo=0, scoring='accuracy', method='SFI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "    print((end-start)/60)\n",
    "    print(f'SFI takes {(end-start)/60/60} hours')\n",
    "    \n",
    "else:  \n",
    "    SFI_imp_Xpp = pd.read_csv('SFI_imp_Xpp.csv')\n",
    "    SFI_oob_oos_Xpp = pd.read_csv('SFI_oob_oos_Xpp.csv')[['value']]\n",
    "    SFI_oob_Xpp = SFI_oob_oos_Xpp.iloc[0,0]\n",
    "    SFI_oos_Xpp = SFI_oob_oos_Xpp.iloc[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set the importance measures in descending order:\n",
    "imp_Xpp_cols = ['features', 'mean', 'std']\n",
    "MDI_imp_Xpp.columns = imp_Xpp_cols\n",
    "MDA_imp_Xpp.columns = imp_Xpp_cols\n",
    "SFI_imp_Xpp.columns = imp_Xpp_cols\n",
    "\n",
    "MDI_imp_Xpp_sorted = MDI_imp_Xpp.sort_values(by=['mean'], ascending=False)\n",
    "MDA_imp_Xpp_sorted = MDA_imp_Xpp.sort_values(by=['mean'], ascending=False)\n",
    "SFI_imp_Xpp_sorted = SFI_imp_Xpp.sort_values(by=['mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_Xpp_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDA_imp_Xpp_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFI_imp_Xpp_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp_Xpp = (pd.DataFrame()\n",
    "                   .assign(features_MDI = MDI_imp_Xpp_sorted['features'].values)\n",
    "                   .assign(MDI_imp = MDI_imp_Xpp_sorted['mean'].values)\n",
    "                   .assign(features_MDA = MDA_imp_Xpp_sorted['features'].values)\n",
    "                   .assign(MDA_imp = MDA_imp_Xpp_sorted['mean'].values)\n",
    "                   .assign(features_SFI = SFI_imp_Xpp_sorted['features'].values)\n",
    "                   .assign(SFI_imp = SFI_imp_Xpp_sorted['mean'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp_Xpp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.2.b) Do the three methods agree on the important features? Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods MDA and MDI do not agree on the important features due to the substitution effect but there is a high coincidence between the selected elements of the MDI and SFI methods, within the first ten selected features, MDI and SFI share 8 out of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3) Take the results from exercise 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3.a) Drop the most important features according to each method, resulting in a features matrix $\\dddot{X}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp_Xpp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_topFeat_Xpp = features_imp_Xpp.features_MDI.head(10).values\n",
    "MDA_topFeat_Xpp = features_imp_Xpp.features_MDA.head(10).values\n",
    "SFI_topFeat_Xpp = features_imp_Xpp.features_SFI.head(10).values\n",
    "\n",
    "\n",
    "print(f'MDI_topFeat_Xpp: {MDI_topFeat_Xpp}')\n",
    "print(f'MDA_topFeat_Xpp: {MDA_topFeat_Xpp}')\n",
    "print(f'SFI_topFeat_Xpp: {SFI_topFeat_Xpp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_MDA_SFI_topFeat_Xpp = np.concatenate((MDI_topFeat_Xpp, MDA_topFeat_Xpp, SFI_topFeat_Xpp), axis=0).tolist()\n",
    "print(f'MDI_MDA_SFI_topFeat_Xpp: {MDI_MDA_SFI_topFeat_Xpp}')\n",
    "\n",
    "# remove duplicates:\n",
    "MDI_MDA_SFI_topFeat_Xpp = list(dict.fromkeys(MDI_MDA_SFI_topFeat_Xpp))\n",
    "print(f'\\nMDI_MDA_SFI_topFeat_Xpp: {MDI_MDA_SFI_topFeat_Xpp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_Xpp = []\n",
    "for c in X_pp.columns:\n",
    "    cols_Xpp.append(str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pp.columns = cols_Xpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ppp = X_pp.drop(columns=MDI_MDA_SFI_topFeat_Xpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ppp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3.b) Compute MDI, MDA, and SFI feature importance on ($\\dddot{X},y$), where the base estimator is RF.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDI_Xppp:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDI = False\n",
    "\n",
    "if calculate_MDI:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_Xppp, MDI_oob_Xppp, MDI_oos_Xppp = featImportance_2_mc(trnsX=X_ppp, cont= trns_y, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI takes {(end-start)/60} minutes')\n",
    "    \n",
    "else:\n",
    "    MDI_imp_Xppp = pd.read_csv('MDI_imp_Xppp.csv', index_col=[0])\n",
    "    MDI_oob_oos_Xppp = pd.read_csv('MDI_oob_oos_Xppp.csv',index_col=[0])\n",
    "    MDI_oob_Xppp = MDI_oob_oos_Xppp.iloc[0,0]\n",
    "    MDI_oos_Xppp = MDI_oob_oos_Xppp.iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_oob_oos_Xppp = (pd.DataFrame(index=['MDI_oob', 'MDI_oos'])\n",
    "                   .assign(values = pd.Series([MDI_oob_Xppp, MDI_oos_Xppp]).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MDA_Xppp:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_MDA = False\n",
    "\n",
    "if calculate_MDA:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDA_imp_Xppp, MDA_oob_Xppp, MDA_oos_Xppp = featImportance_2_mc(trnsX=X_ppp, cont= trns_y, n_estimators=1000, cv=10, max_samples=1.,\n",
    "                       pctEmbargo=0, scoring='accuracy', method='MDA', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'MDA takes {(end-start)/60} minutes')\n",
    "    \n",
    "else:\n",
    "    MDA_imp_Xppp = pd.read_csv('MDA_imp_Xppp.csv', index_col=[0])\n",
    "    MDA_oob_oos_Xppp = pd.read_csv('MDA_oob_oos_Xppp.csv', index_col=[0])\n",
    "    MDA_oob_Xppp = MDA_oob_oos_Xppp.iloc[0,0]\n",
    "    MDA_oos_Xppp = MDA_oob_oos_Xppp.iloc[1,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDA_oob_oos_Xppp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "**SFI_Xppp:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_SFI = False\n",
    "\n",
    "if calculate_SFI:\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    SFI_imp_Xppp, SFI_oob_Xppp, SFI_oos_Xppp = featImportance_2_mc(trnsX=X_ppp, cont= trns_y, n_estimators=1000, cv=10, max_samples=1.,\n",
    "                       pctEmbargo=0, scoring='accuracy', method='SFI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "    print((end-start)/60)\n",
    "    print(f'SFI takes {(end-start)/60/60} hours')\n",
    "    \n",
    "else:  \n",
    "    SFI_imp_Xppp = pd.read_csv('SFI_imp_Xppp.csv', index_col = [0])\n",
    "    SFI_oob_oos_Xppp = pd.read_csv('SFI_oob_oos_Xppp.csv', index_col = [0])\n",
    "    SFI_oob_Xppp = SFI_oob_oos_Xppp['SFI_oob'].values[0]\n",
    "    SFI_oos_Xppp = SFI_oob_oos_Xppp['SFI_oos'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set the importance measures in descending order:\n",
    "imp_Xppp_cols = ['mean', 'std']\n",
    "MDI_imp_Xppp.columns = imp_Xppp_cols\n",
    "MDA_imp_Xppp.columns = imp_Xppp_cols\n",
    "SFI_imp_Xppp.columns = imp_Xppp_cols\n",
    "\n",
    "MDI_imp_Xppp_sorted = MDI_imp_Xppp.sort_values(by=['mean'], ascending=False)\n",
    "MDA_imp_Xppp_sorted = MDA_imp_Xppp.sort_values(by=['mean'], ascending=False)\n",
    "SFI_imp_Xppp_sorted = SFI_imp_Xppp.sort_values(by=['mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame with importance measures sorted:\n",
    "\n",
    "features_imp_Xppp = (pd.DataFrame()\n",
    "                     .assign(MDI_features = MDI_imp_Xppp_sorted.index)\n",
    "                     .assign(MDI_imp = MDI_imp_Xppp_sorted['mean'].values)\n",
    "                     .assign(MDA_features = MDA_imp_Xppp_sorted.index)\n",
    "                     .assign(MDA_imp = MDA_imp_Xppp_sorted['mean'].values)\n",
    "                     .assign(SFI_features = SFI_imp_Xppp_sorted.index)\n",
    "                     .assign(SFI_imp = SFI_imp_Xppp_sorted['mean'].values)\n",
    "                    )\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_imp_Xppp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.3.c) Do you appreciate significant changes in the rankings of important features, relative to the results from exercise 2?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the 10 most important features issued for the three methods, the results from the previous dataset ($\\ddot{X},y$) showed 3 coincidences out of 10 between MDI and MDA, and for the dataset ($\\dddot{X},y$) the coincidences rose up to 9 out of 10.\n",
    "\n",
    "Regarding the matches between MDI and SFI they fell from 8 to 5 out of 10. It is worth to note that all three methods share the first 4 most important features.\n",
    "\n",
    "Despite most of informative features were dropped in order to generate the set XÂ°Â°Â°, the only two informative features I_2 and I_7 were selected by MDI and MDA methods, for the case of SFI I_2 was not selected among the ten most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4)Using the code presented in Section 8.6:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4.a) Generate a dataset (X,y) of 1E6 observations, where 5 features are imformative, 5 are redundant and 10 are noise.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generating the 1E6 observations with the function $getTestData()$ it issues an error in the statement that creates the index with the method $DatetimeIndex()$. It seems that the function allows certain amount of datetime elements to be created (about 70.000 under the BusinessDay frequency), then a suggested modification to solve this contrariness is to change the frequence from BusinessDay to 15 minutes periods:\n",
    "\n",
    "$df0=pd.DatetimeIndex(periods=$n_samples$,freq=pd.tseries.offsets.Minute(30), end=pd.datetime.today())$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datasets = 10\n",
    "n_samples_8 = 1000000\n",
    "n_features_8 = 20\n",
    "n_informative_8 = 5\n",
    "n_redundant_8 = 5\n",
    "\n",
    "X8, y8 = getTestData_largeSet(n_features=n_features_8, n_informative=n_informative_8, \n",
    "                                  n_redundant=n_redundant_8, n_samples=n_samples_8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4.b) Split (X,y) into 10 datasets {($X_{i}$,$y_{i}$)}$_{i=1,....,10}$, each of 1E5 observations.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets come already ordered that way from the exercise (8.4.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X8_datasets = []\n",
    "y8_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.array_split(np.arange(n_samples_8),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ind)):\n",
    "    X8_datasets.append(X8.iloc[ind[i],:])\n",
    "    y8_datasets.append(y8.iloc[ind[i],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of observations of dataset [0]: {X8_datasets[0].shape}')\n",
    "print(f'Number of observations of dataset [9]: {X8_datasets[9].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4.c) Compute the parallelized feature importance (Section 8.5), on each of the 10 datasets, {($X_{i}$,$y_i$)}$_{i=1,....10}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following processing takes more than 9 hours just calculating MDI without a parallel process,\n",
    "# then in order to skip it, the variable \"processing\" is set to False \n",
    "# heading off to a cell ahead where a DataFrame with the results sorted are uploaded.\n",
    "\n",
    "#(The multiprocess is covered in chapter 20)\n",
    "\n",
    "processing = False \n",
    "\n",
    "if processing:\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_dict = {}\n",
    "    MDI_oob_dict = {}\n",
    "    MDI_oos_dict = {}\n",
    "\n",
    "    for i in range(len(X8_datasets)):\n",
    "        MDI_imp, MDI_oob, MDI_oos = featImportance_2_mc(trnsX=X8_datasets[i], cont= y8_datasets[i], n_estimators=1000, \n",
    "                                                        cv=cv, max_samples=max_samples,pctEmbargo=pctEmbargo, \n",
    "                                                        scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "        MDI_imp_dict['MDI_imp_'+str(i)] = MDI_imp\n",
    "        MDI_oob_dict['MDI_oob_'+str(i)] = MDI_oob\n",
    "        MDI_oos_dict['MDI_oos_'+str(i)] = MDI_oos\n",
    "\n",
    "        print(f'iteracion {i}')\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'Parallelized feature importance calculation takes {(end-start)/60/60} hours')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this cell sets the results of the \"MDI_imp_dict\" in DataFrames, one for the column 'mean' which the \n",
    "# MDI value and other for the column 'std'.\n",
    "# As the results were already carried out and saved, the staments are within a conditional\n",
    "# that allows to skip them.\n",
    "\n",
    "if processing == True:\n",
    "\n",
    "    \n",
    "    MDI_keys = list(MDI_imp_dict.keys())\n",
    "    MDI_imp_mean_ALL = pd.DataFrame(index=MDI_imp_dict[MDI_keys[0]].index)\n",
    "    MDI_imp_std_ALL = pd.DataFrame(index=MDI_imp_dict[MDI_keys[0]].index)\n",
    "        \n",
    "    count = 0\n",
    "\n",
    "    for key in MDI_imp_dict:\n",
    "        MDI_imp_mean_df = pd.DataFrame()\n",
    "        MDI_imp_mean_df = MDI_imp_dict[key]\n",
    "        MDI_imp_mean_ALL['mean_'+str(count)] = MDI_imp_mean_df['mean'].values\n",
    "        \n",
    "        MDI_imp_std_df = pd.DataFrame()\n",
    "        MDI_imp_std_df = MDI_imp_dict[key]\n",
    "        MDI_imp_std_ALL['std_'+str(count)] = MDI_imp_std_df['std'].values\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "else:\n",
    "    MDI_imp_mean_ALL = pd.read_csv('MDI_imp_parallelized.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell orders the content of the dictionary with oob and oos values into a DataFrame.\n",
    "# The content can be loaded setting \"processing = False\"\n",
    "\n",
    "if processing:\n",
    "\n",
    "    MDI_oob = []\n",
    "    MDI_oos = []\n",
    "\n",
    "    for key, value in MDI_oob_dict.items():\n",
    "        MDI_oob.append(value)\n",
    "\n",
    "    for key, value in MDI_oos_dict.items():\n",
    "        MDI_oos.append(value)\n",
    "\n",
    "    MDI_oob_oos = pd.DataFrame({'MDI_oob':MDI_oob, 'MDI_oos':MDI_oos})\n",
    "\n",
    "else:\n",
    "    MDI_oob_oos = pd.read_csv('MDI_oob_oos_parallelized.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the global value of MDI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_mean_ALL['sum'] = MDI_imp_mean_ALL.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_mean_ALL_sorted = MDI_imp_mean_ALL.sort_values(by=['sum'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_mean_ALL_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4.d) Compute the stacked feature importance on the combined dataset (X,y).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a distributional homogeneity is inherent across all datasets {($\\tilde{X}_{i}$,$y{i}$)}$_{i=1,...,10}$ due to its generation methodology, no transformation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The calculation process without parallelization takes about 15 hours so the conditional is created to upload the \n",
    "# results previously calculated.\n",
    "\n",
    "processing = False\n",
    "\n",
    "if processing:\n",
    "    start = time.time()\n",
    "    MDI_imp_stacked, MDI_oob_stacked, MDI_oos_stacked = featImportance_2_mc(trnsX=X8, cont= y8, n_estimators=1000, \n",
    "                                                            cv=cv, max_samples=max_samples,pctEmbargo=pctEmbargo, \n",
    "                                                            scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "    print(f'The calculation of the MDI for the combined dataset takes {(end-start)/60/60} hours')\n",
    "\n",
    "else:\n",
    "    MDI_imp_stacked = pd.read_csv('MDI_imp_stacked.csv', index_col = [0])\n",
    "    MDI_oob_oos_stacked = pd.read_csv('MDI_oob_oos_stacked.csv', index_col = [0])\n",
    "    MDI_oob_stacked = MDI_oob_oos_stacked.iloc[0,0]\n",
    "    MDI_oos_stacked = MDI_oob_oos_stacked.iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_stacked_sorted = MDI_imp_stacked.sort_values(by = ['mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_stacked_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.4.e) What causes the discrepancy between the two?$\\quad$ Which one is more reliable?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the discrepancy between the results from the parellelzed methodology and the stacked methodology, the 10 most important features coincide in both cases. The order is not exactly the same but the same 10 features are selected in both methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to the relibility of the results, as they coincide, the stacked methodology is more reliable due to the following advantages as it is mentioned in AFML section 8.5:\n",
    "\n",
    "1)The classifier is fitted on a much larger dataset.\n",
    "\n",
    "2)The importance is derived directly, and no weighting scheme is required for combining the results.\n",
    "\n",
    "3)Conclusions are more general and less biased by outliers or overfitting.\n",
    "\n",
    "4)Because importance scores are not averaged across instruments, substitution effects do not cause the dampening of those scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.5) Repeat all MDI calculations from exercises 1-4, but this time allow for masking effects. That means, do not set $max$_$features=int(1)$ in Snippet 8.2.$\\quad$How do results differ as a consequence of this change? $\\quad$Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNIPPET 8.8 CALLING FEATURE IMPORTANCE FOR ANY METHOD - Allowing masking effects:\n",
    "\n",
    "   # It is the same function used to calculate feature importance but it includes a modification.\n",
    "   # The parameter \"max_features\" within the methods \"DecisionTreeClassifier()\" is set to \"None\", which is equivalent \n",
    "   # to set max_features = n_features.\n",
    "    \n",
    "\n",
    "def featImportance_2_mc_msk(trnsX,cont,n_estimators=1000,cv=10,max_samples=1.,\n",
    "                   pctEmbargo=0,scoring='accuracy',method='SFI',minWLeaf=0.,**kargs):\n",
    "    \n",
    "    # feature importance from a random forest\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import BaggingClassifier\n",
    "    #from mpEngine import mpPandasObj                  #mc\n",
    "    \n",
    "    # n_jobs=(-1 if numThreads>1 else 1) # run 1 thread with ht_helper in dirac1    ...#mc\n",
    "    \n",
    "    #1) prepare classifier,cv. max_features=1, to prevent masking\n",
    "    \n",
    "    clf=DecisionTreeClassifier(criterion='entropy',max_features=None,class_weight='balanced',   \n",
    "                               min_weight_fraction_leaf=minWLeaf)                   # mc\n",
    "    \n",
    "    #clf=BaggingClassifier(base_estimator=clf,n_estimators=n_estimators,            ...#mc\n",
    "    #                        max_features=1.,max_samples=max_samples,oob_score=True,n_jobs=n_jobs)\n",
    "    \n",
    "    #To include making effects as required in the exercise 8.5, the parameter max_features of the BaggingClassifier is \n",
    "    # is set to 1. according to:\n",
    "    \n",
    "    #            max_features = If float, then draw max_features * X.shape[1] features\n",
    "    \n",
    "    clf=BaggingClassifier(base_estimator=clf,n_estimators=n_estimators,max_features=1.,\n",
    "                          max_samples=max_samples,oob_score=True)\n",
    "    fit=clf.fit(X=trnsX,y=cont['bin'],sample_weight=cont['w'].values)\n",
    "    oob=fit.oob_score_\n",
    "    \n",
    "    if method=='MDI':\n",
    "        imp=featImpMDI(fit,featNames=trnsX.columns)\n",
    "        \n",
    "        #oos=cvScore(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],                     #original\n",
    "        #            t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring).mean()\n",
    "        \n",
    "        oos = cvScore2_mc(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],                # mc\n",
    "                          t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring).mean()\n",
    "              \n",
    "    elif method=='MDA':\n",
    "        imp,oos=featImpMDA(clf,X=trnsX,y=cont['bin'],cv=cv,sample_weight=cont['w'],\n",
    "                           t1=cont['t1'],pctEmbargo=pctEmbargo,scoring=scoring)\n",
    "    \n",
    "    elif method=='SFI':\n",
    "        cvGen=PurgedKFold(n_splits=cv,t1=cont['t1'],pctEmbargo=pctEmbargo)\n",
    "        \n",
    "        #oos=cvScore(clf,X=trnsX,y=cont['bin'],sample_weight=cont['w'],scoring=scoring,           #original\n",
    "        #            cvGen=cvGen).mean()\n",
    "        \n",
    "        oos = cvScore2_mc(clf, X=trnsX,y=cont['bin'],sample_weight=cont['w'],scoring=scoring,     #...mc\n",
    "                                cvGen=cvGen).mean()\n",
    "        \n",
    "        #clf.n_jobs=1 # paralellize auxFeatImpSFI rather than clf                                 # original\n",
    "        #imp=mpPandasObj(auxFeatImpSFI,('featNames',trnsX.columns),numThreads,\n",
    "        #                clf=clf,trnsX=trnsX,cont=cont,scoring=scoring,cvGen=cvGen)\n",
    "        \n",
    "        \n",
    "        imp = auxFeatImpSFI(featNames=trnsX.columns, clf=clf, trnsX=trnsX, cont=cont, scoring=scoring, cvGen=cvGen)     #mc\n",
    "        \n",
    "        \n",
    "    return imp,oob,oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.1 Using the code presented in Section 8.6:\n",
    "\n",
    "# 8.5 - 8.1(a) Generate a dataset (X, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"msk\" suffix is to denote \"masking effects\"\n",
    "\n",
    "X_msk, y_msk = getTestData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.1(b) Apply a PCA transformation on X, which we denote ÌX.\n",
    "\n",
    "Xp_msk = orthoFeats(X_msk, varThres = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_msk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.1(c) Compute MDI feature importance on (ÌX, y), where the base estimator is RF. (just MDI)\n",
    "\n",
    "# MDI:\n",
    "\n",
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1.\n",
    "\n",
    "calculate_MDI_msk = False\n",
    "\n",
    "if calculate_MDI_msk:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_msk, MDI_oob_msk, MDI_oos_msk = featImportance_2_mc_msk(trnsX=Xp_msk, cont= y_msk, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI_msk takes {(end-start)/60} minutes')\n",
    "    \n",
    "else:\n",
    "    MDI_imp_msk = pd.read_csv('MDI_imp_msk.csv', index_col=[0])\n",
    "    MDI_oob_oos_msk = pd.read_csv('MDI_oob_oos_msk.csv', index_col = [0])\n",
    "    MDI_oob_msk = MDI_oob_oos_msk.iloc[0,0]\n",
    "    MDI_oos_msk = MDI_oob_oos_msk.iloc[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) Do the three methods agree on the important features?  Why?\n",
    "\n",
    "# In this case the question would be, do the MDI results calculated not allowing mask effects agree with the \n",
    "# MDI results allowing mask effects?\n",
    "\n",
    "MDI_imp_msk_sorted = MDI_imp_msk.sort_values(by=['mean'], ascending = False)\n",
    "MDI_imp_sorted = MDI_imp.sort_values(by = ['mean'], ascending = False)\n",
    "\n",
    "MDI_imp_results = (pd.DataFrame()\n",
    "                  .assign(MDI_feat = MDI_imp_sorted.index)\n",
    "                  .assign(MDI = MDI_imp_sorted['mean'].values)\n",
    "                  .assign(MDI_msk_feat = MDI_imp_msk_sorted.index)\n",
    "                  .assign(MDI_msk = MDI_imp_msk_sorted['mean'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the 10 most important features selected for both methodolgies, there is a coincide in 9 out of 10. It seems the masking effects that consist on systematically ignore some features by the tree classifiers did not take place or it took place in both cases. Let's see the following results where the calculations are over the principal components.\n",
    "\n",
    "The modifications in order to perform the results allowing the mask effects consist in setting the parameter (max_features=None) to the classifier clf=DecisionTreeClassifier( ....,..., max_features=None,...) and the same parameter (max_features = 1.)(1. is a float number) to the classifier clf=BaggingClassifier(...,...,max_features=1.,...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.2) From exercise 1, generate a new dataset (XÌ , y), where XÌ is a feature union of X and ÌX.\n",
    "\n",
    "Xpp_msk = pd.concat([X_msk, Xp_msk], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpp_msk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpp_msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.2.a) Compute MDI, MDA, and SFI feature importance on (XÌ , y), where the base estimator is RF.\n",
    "#              (Compute MDI feature importance on (XÌ,ð¦) , where the base estimator is RF.)\n",
    "\n",
    "# MDI for Xpp_msk:\n",
    "\n",
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1.\n",
    "\n",
    "calculate_MDI_msk_Xpp = False\n",
    "\n",
    "if calculate_MDI_msk_Xpp:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_msk_Xpp, MDI_oob_msk_Xpp, MDI_oos_msk_Xpp = featImportance_2_mc_msk(trnsX=Xpp_msk, cont= y_msk, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI_msk_Xpp takes {(end-start)/60} minutes')\n",
    "    \n",
    "else:\n",
    "    MDI_imp_msk_Xpp = pd.read_csv('MDI_imp_msk_Xpp.csv', index_col=[0])\n",
    "    MDI_oob_oos_msk_Xpp = pd.read_csv('MDI_oob_oos_msk_Xpp.csv', index_col = [0])\n",
    "    MDI_oob_msk_Xpp = MDI_oob_oos_msk_Xpp.iloc[0,0]\n",
    "    MDI_oos_msk_Xpp = MDI_oob_oos_msk_Xpp.iloc[1,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.2.b) Do the three methods agree on the important features? Why? \n",
    "#              In this case the question would be: \n",
    "#              Do the MDI results allowing mask effects calculated upon the X' agree to the MDI (mask effects allowed)\n",
    "#              results calculated on X?\n",
    "# \n",
    "#              Other interesting question could be: Do the MDI results allowing mask effects calculated upon the X'\n",
    "#              agree to the MDI without mask effects (upon the same dataset X')?\n",
    "\n",
    "MDI_imp_sorted\n",
    "MDI_imp_msk_Xpp_sorted = MDI_imp_msk_Xpp.sort_values(by=['mean'], ascending = False)\n",
    "\n",
    "MDI_msk_Xp_Xpp = (pd.DataFrame()\n",
    "                  .assign(Xp_features = MDI_imp_sorted.index)\n",
    "                  .assign(MDI_Xp = MDI_imp_sorted['mean'].values)\n",
    "                  .assign(Xpp_features = MDI_imp_msk_Xpp_sorted.index[:len(MDI_imp_sorted.index)])\n",
    "                  .assign(MDI_Xpp = MDI_imp_msk_Xpp_sorted['mean'].values[:len(MDI_imp_sorted.index)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_msk_Xp_Xpp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Xp_features* are integers because they refer to PCA that comprise the 95% of the variation of the original data set, while the *Xpp_features* include the name of certain features because the dataset XÂ°Â° is composed by the aforementioned PCA and the original features of the original dataset.\n",
    "\n",
    "The results of MDI allowing masking effects calculated over the X and XÂ°Â° datasets agree only on one feature, the first principal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the MDI results allowing mask effects calculated upon the XÂ° agree with \n",
    "# the MDI without mask effects (upon the same dataset XÂ°)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_msk_Xpp_sorted = MDI_imp_msk_Xpp.sort_values(by=['mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_Xpp_comparison_results = (pd.DataFrame()\n",
    "                  .assign(features_Xpp = MDI_imp_Xpp_sorted['features'])\n",
    "                  .assign(MDI_Xpp = MDI_imp_Xpp_sorted['mean'].values)\n",
    "                  .assign(features_msk = MDI_imp_msk_Xpp_sorted.index)\n",
    "                  .assign(MDI_Xpp_msk = MDI_imp_msk_Xpp_sorted['mean'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_Xpp_comparison_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the most important selected features there are coincidences in 6 out of 10 features. The masking effects become more evident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.3) Take the results from exercise 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.3.a) Drop the most important features according to each method (MDI in this exercise), \n",
    "# resulting in a features matrix  XÂ°Â°Â°."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_msk_Xp_Xpp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_msk_topFeatures = list(MDI_msk_Xp_Xpp['Xp_features'].head(10).values)\n",
    "print(f'Xp_msk_topFeatures: {Xp_msk_topFeatures}')\n",
    "\n",
    "Xpp_msk_topFeatures = list(MDI_msk_Xp_Xpp['Xpp_features'].head(10).values)\n",
    "print(f'\\nXpp_msk_topFeatures: {Xpp_msk_topFeatures}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpp_msk_features_drop = Xp_msk_topFeatures + Xpp_msk_topFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some features stored in Xppp_msk_features_all have int() format as a consecuence of the orthogonalization (PCA calculation), \n",
    "# so it is necessary to transform them to str() format.\n",
    "\n",
    "Xpp_features_str = []\n",
    "for f in Xpp_msk_features_drop:\n",
    "    Xpp_features_str.append(str(f))\n",
    "\n",
    "Xpp_msk_features_drop = Xpp_features_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Remove duplicates:\n",
    "\n",
    "Xpp_msk_features = []\n",
    "\n",
    "for feat in Xpp_msk_features_drop:\n",
    "    if feat not in Xpp_msk_features:\n",
    "        Xpp_msk_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all the columns names to strings:\n",
    "Xpp_cols = []\n",
    "for col in Xpp_msk.columns:\n",
    "    Xpp_cols.append(str(col))\n",
    "\n",
    "Xpp_msk.columns = Xpp_cols\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xppp_msk = Xpp_msk.drop(Xpp_msk_features_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xppp_msk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.5. - 8.3.b) Compute MDI feature importance on (XÂ°Â°Â°, y), where the base estimator is RF.\n",
    "\n",
    "# MDI for Xpp_msk:\n",
    "\n",
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1.\n",
    "\n",
    "calculate_MDI_msk_Xppp = False\n",
    "\n",
    "if calculate_MDI_msk_Xppp:\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    MDI_imp_msk_Xppp, MDI_oob_msk_Xppp, MDI_oos_msk_Xppp = featImportance_2_mc_msk(trnsX=Xppp_msk, cont= y_msk, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                       pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'MDI_msk_Xpp takes {(end-start)/60} minutes')\n",
    "    \n",
    "    MDI_imp_msk_Xppp.to_csv('MDI_imp_msk_Xppp.csv')\n",
    "    \n",
    "    MDI_oob_oos_msk_Xppp = pd.DataFrame({'values':[MDI_oob_msk_Xppp, MDI_oos_msk_Xppp]}, index=['MDI_oob','MDI_oos'])\n",
    "    MDI_oob_oos_msk_Xppp.to_csv('MDI_oob_oos_msk_Xppp.csv')\n",
    "    \n",
    "else:\n",
    "    MDI_imp_msk_Xppp = pd.read_csv('MDI_imp_msk_Xppp.csv', index_col=[0])\n",
    "    MDI_oob_oos_msk_Xppp = pd.read_csv('MDI_oob_oos_msk_Xppp.csv', index_col = [0])\n",
    "    MDI_oob_msk_Xppp = MDI_oob_oos_msk_Xppp.iloc[0,0]\n",
    "    MDI_oos_msk_Xppp = MDI_oob_oos_msk_Xppp.iloc[1,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_msk_Xppp_sorted = MDI_imp_msk_Xppp.sort_values(by=['mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_msk_Xppp_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.3.c) Do you appreciate significant changes in the rankings of important features, relative to the results \n",
    "#           from exercise 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_imp_msk_Xpp_sorted.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_Xpp_Xppp_results = (pd.DataFrame()\n",
    "                       .assign(Xpp_msk_feat = MDI_imp_msk_Xpp_sorted.index[:MDI_imp_msk_Xppp_sorted.shape[0]])\n",
    "                       .assign(MDI_Xpp = MDI_imp_msk_Xpp_sorted['mean'].values[:MDI_imp_msk_Xppp_sorted.shape[0]])\n",
    "                       .assign(Xppp_msk_feat = MDI_imp_msk_Xppp_sorted.index)\n",
    "                       .assign(MDI_Xppp = MDI_imp_msk_Xppp_sorted['mean'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MDI_Xpp_Xppp_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not coincidences among the first 10 most important features selected for both datasets, remember that the XÂ°Â°Â° dataset is generated droping the most important features in XÂ°Â°. Neverthelesss the features are quite similar regarding its kind, for instance the informative features selected in the XÂ°Â° dataset are close to the informative features selected in the XÂ°Â°Â° dataset, let's see:\n",
    "\n",
    "*XÂ°Â°=(I_0, I_2, I_4, I_6, I_8, I_9)*\n",
    "\n",
    "*XÂ°Â°Â°=(I_1, I_3, I_5, I_7)*\n",
    "\n",
    "Among both selected features sets are the informative ones which is coherent with the objective of the exercise. \n",
    "It is worth to mention that in spite of the mask effects allowed in this exercise the selected features were the most important. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.4) Using the code presented in Section 8.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.4.a) Generate a dataset (X,y) of 1E6 observations, where 5 features are informative, 5 are redundant and 10 are noise.\n",
    "\n",
    "n_datasets = 10\n",
    "n_samples_8 = 1000000\n",
    "n_features_8 = 20\n",
    "n_informative_8 = 5\n",
    "n_redundant_8 = 5\n",
    "\n",
    "Xmsk_e8, ymsk_e8 = getTestData_largeSet(n_features=n_features_8, n_informative=n_informative_8, \n",
    "                                  n_redundant=n_redundant_8, n_samples=n_samples_8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Xmsk_e8.shape: {Xmsk_e8.shape}')\n",
    "print(f'ymsk_e8.shape: {ymsk_e8.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.4.b) Split (X, y) into 10 datasets {(Xi, yi)}i=1,â¦,10, each of 1E5 observations.\n",
    "\n",
    "indices = np.array_split(np.arange(Xmsk_e8.shape[0]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_datasets_msk = []\n",
    "y_datasets_msk = []\n",
    "\n",
    "for i in indices:\n",
    "    X_datasets_msk.append(Xmsk_e8.iloc[i[0]:i[-1]+1,:])\n",
    "    y_datasets_msk.append(ymsk_e8.iloc[i[0]:i[-1]+1,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.4.c) Compute the parallelized feature importance (Section 8.5), on each of the 10\n",
    "# datasets, {(Xi, yi)}i=1,â¦,10.\n",
    "\n",
    "\n",
    "# MDI for X_datasets_msk:\n",
    "\n",
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1.\n",
    "\n",
    "calculate_MDI_msk_85_84c = False\n",
    "\n",
    "if calculate_MDI_msk_85_84c:\n",
    "\n",
    "    start_global = time.time()\n",
    "    MDI_msk_85_84c_list = []\n",
    "    \n",
    "    for i in range(len(X_datasets_msk)):\n",
    "        print(f'iteration {i}')\n",
    "        start_i = time.time()\n",
    "\n",
    "        MDI_imp_msk_85_84c, MDI_oob_msk_85_84c, MDI_oos_msk_85_84c = featImportance_2_mc_msk(trnsX=X_datasets_msk[i], cont= y_datasets_msk[i], n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                           pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "        \n",
    "        MDI_msk_85_84c_list.append(MDI_imp_msk_85_84c)\n",
    "        end_i = time.time()\n",
    "        \n",
    "        print(f'elapsed time: {(end_i-start_i)/60} minutes')\n",
    "\n",
    "    end_global = time.time()\n",
    "\n",
    "    print(f'All MDI_msk_85_84c takes {(end_global-start_global)/60} minutes')\n",
    "    \n",
    "    MDI_msk_85_84c = (pd.DataFrame()\n",
    "                 .assign(features_1 = MDI_msk_85_84c_list[0].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_1 = MDI_msk_85_84c_list[0].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_2 = MDI_msk_85_84c_list[1].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_2 = MDI_msk_85_84c_list[1].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_3 = MDI_msk_85_84c_list[2].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_3 = MDI_msk_85_84c_list[2].sort_values(by=['mean'], ascending=False)['mean'].values) \n",
    "                 .assign(features_4 = MDI_msk_85_84c_list[3].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_4 = MDI_msk_85_84c_list[3].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_5 = MDI_msk_85_84c_list[4].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_5 = MDI_msk_85_84c_list[4].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_6 = MDI_msk_85_84c_list[5].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_6 = MDI_msk_85_84c_list[5].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_7 = MDI_msk_85_84c_list[6].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_7 = MDI_msk_85_84c_list[6].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_8 = MDI_msk_85_84c_list[7].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_8 = MDI_msk_85_84c_list[7].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_9 = MDI_msk_85_84c_list[8].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_9 = MDI_msk_85_84c_list[8].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 .assign(features_10 = MDI_msk_85_84c_list[9].sort_values(by=['mean'], ascending=False).index)\n",
    "                 .assign(MDI_10 = MDI_msk_85_84c_list[9].sort_values(by=['mean'], ascending=False)['mean'].values)\n",
    "                 )\n",
    "    \n",
    "    MDI_msk_85_84c.to_csv('MDI_msk_85_84c.csv')\n",
    "    \n",
    "    \n",
    "else: \n",
    "    MDI_msk_85_84c = pd.read_csv('MDI_msk_85_84c.csv', index_col = [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDI_msk_85_84c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.5 - 8.4.d) Compute the stacked feature importance on the combined dataset (X, y).\n",
    "\n",
    "# MDI for the stacked dataset_msk:\n",
    "\n",
    "cv = 10\n",
    "pctEmbargo = 0\n",
    "max_samples = 1.\n",
    "\n",
    "calculate_MDI_msk_85_84d = True\n",
    "\n",
    "if calculate_MDI_msk_85_84d:\n",
    "\n",
    "    start_global = time.time()\n",
    "    \n",
    "    MDI_imp_msk_85_84d, MDI_oob_msk_85_84d, MDI_oos_msk_85_84d = featImportance_2_mc_msk(trnsX=Xmsk_e8, cont= ymsk_e8, n_estimators=1000, cv=cv, max_samples=max_samples,\n",
    "                           pctEmbargo=pctEmbargo, scoring='accuracy', method='MDI', minWLeaf=0.)\n",
    "\n",
    "    end_global = time.time()\n",
    "\n",
    "    print(f'All MDI_msk_85_84d takes {(end_global-start_global)/60} minutes')\n",
    "    \n",
    "    MDI_imp_msk_85_84d_sorted = MDI_imp_msk_85_84d.sort_values(by=['mean'], ascending=False) \n",
    "    \n",
    "    MDI_imp_msk_85_84d_sorted.to_csv('MDI_imp_msk_85_84d.csv')\n",
    "\n",
    "else:\n",
    "    MDI_imp_msk_85_84d = pd.read_csv('MDI_imp_msk_85_84d.csv', index_col = [0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
